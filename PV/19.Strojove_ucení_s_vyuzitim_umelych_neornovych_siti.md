# 19. Strojové učení s využitím umělých neuronových sítí


## Umělá neuronová síť
- Jejím vzorem je chování odpovídajících biologických struktur -> neuronů
- Určena pro distribuované paralelní zpracování dat

<br>

### Perecptron -> neuronová síť s jedním neuronem
  - Jednoduchá matematická funkce, která má N vstupů (x1...xN) a jeden výstup
  - Každý vstup pronásobí určitou váhou (w1...wN) 
  - Vstupní výsledky (xN krát wN) sečte a získá tím hodnotu Z.
  - Poslední vstup 1 krát w0 = BIAS -> Lineární posun (BIAS SE VYSKYTUJE VŽDY!!)
  - Hodnota Z vstupuje do aktivační funkce (linerání, sigmoid, hyperbolický tangens..) a výstupem je hodnota Y
    - Sigmoid generuje pravděpodobnost (číslo 0 - 1) = většinou poslední výstup
    - Hyperbolický tangens (číslo -1 - 1) = vhodný pro vstup do dalšího neuronu, protože hodnota je normalizovaná

<br>

 
 ![perceptron](https://user-images.githubusercontent.com/84131825/233793022-c5c28390-98a7-463c-8724-77280f42eabd.png)

<br>


### Neuronová síť 
 - Posloupnost navzájem propojených vrstev neuronů
 - Parametry na začátku neznáme, jejich úprava je předmětem trénování!

![neuronova_sit](https://user-images.githubusercontent.com/84131825/233836365-2ad9e867-5d29-435a-a252-ed54b0b69cbf.png)

Dvouvrstvá neuronová síť - obrázek
- První vrstva (L1) tvořena 2 neurony, do kterých vstupují všechny vstupy X1...X3
- Druhá vrtsva (L2) tvořena 1 neuronem, do kterého vstupují výstupy z neuronů L2 * příslušné váhy. 

### Trénování sítě
- Hledáme kombinaci parametrů, která produkuje nejmenší chybu sítě
- Trénovací parametry jsou reprezentovány 
  - Vstupními trénovacími hodnotami (X1...Xn)
  - Výstupní trénovací hodnotou (Y)
- Váhy (W) zpočátku vybíráme náhodně
- Chyba je u různých funkcí definovaná různě.. u regrese je například definovaná kvadrátem rozdílů 2 hodnot

![kvadrat](https://user-images.githubusercontent.com/84131825/233836916-c0c44deb-b1fb-40a7-ab3d-c31cdad76e57.png)

Kvadratická chyba u regrese
Y... hodnota kterou bychom chtěli
Y^... hodnota kterou jsme dostali


#### Algoritmus zpětné propagace chyby
- Využívá dynamického programování (ukládá si vypočítané chyby, aby je později mohl znovu využít)
- U větších sítí se algoritmus upravuje..

##### Postup
 - Vybereme vstupní hodnoty a na jejich základě spočítáme výstupní hodnotu
 - Výstupní hodnotu porovnáme s hodnotou, kterou bychom chtěli => viz. chybová funkce
 - Na základě chybové funkce spočítáme jak bychom měli upravit hodnoty, které do výstupního neuronu vstupují
 - Tento algoritmus opakujeme dokud nedojdeme na začátek sítě - L1 => tzv. propagujeme chybu

## Deep learning
 ### Hluboké sítě
 - Tak nazýváme sítě s velkým množstvím vrstev
 - Neuronové sítě známe již od 60. let minulého století, nicméně vzhledem k nedostatečnému výpočetnímu výkonu jsme sítě s vysokým počtem vrstev považovali za zbytečné (neměli žádnou přidanou hodnotu). Souvisí to s algoritmem zpětné propagace -> Čím více vrstev, tím menší úpravy chyby u vstupu.
 - Změnu přinesli grafické karty, které umožňovali vysokou míru paralelizace. Nyní i malá změna na vstupu udělala velký rozdíl a síť mohla být lépe natrénována.
